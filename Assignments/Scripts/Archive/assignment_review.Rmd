---
title: "Class 5 script"
output: html_document
---

```{r setup, include=FALSE}
# Load libraries
library(tidyverse)
library(rpart)
library(rpart.plot)
```

## Agenda

1.  Review module 4 R quiz.

2.  Review portions of the last project.

3.  Prepare for module 5 project. I hope you have noticed that the code in the webinar can be adapted pretty directly for the project!

Avoid frustration! If you hit an obstacle in the project (which is making you feel like hitting something), please get in touch with us!

## R Quiz

```{r}
# Load day data
day <- read.csv("https://raw.githubusercontent.com/jefftwebb/data/main/day.csv")

# Examine structure
str(day)
```

Questions:

-   Is there a relationship between windspeed and temperature in the bike ridership data? What plot type would you choose to explore this question?

-   What is average ridership, conditional on season, in 2011? Match the seasonal with the correct average. Averages have been rounded to the nearest whole number.

-   How many more riders rented bikes in 2012 than in 2011?

```{r}
# Windspeed vs. temperature

ggplot(day, aes(x = temp, y = windspeed)) +
  geom_point() +
  geom_smooth(method= "lm", se = F)


# Average ridership, conditional on season, in 2011

day |> 
  group_by(season) |> 
  summarize(avg_riders = mean(cnt))


# How many more riders rented bikes in 2012 than in 2011?

day |> 
  group_by(yr) |> 
  summarize(total = sum(cnt))

sum(filter(day, yr == )$cnt) - sum(filter(day, yr == 0)$cnt)


```

## Data prep for AdviseInvest

Here is the data prep code chunk that is included in the template. Use this exactly! **The same code will also be available in the template for the Module 5 project.**

```{r}
read_csv("adviseinvest.csv")  |>                             # Download data
  select(-product) |>                                        # Remove the product column
  filter(income > 0,                                          # Filter out mistaken data
         num_accts < 5) |>                                   # This is an arbitrary threshold
  mutate(answered = factor(ifelse(answered==0, "no","yes"),   # Turn answered into yes/no factor
                           levels  = c("no", "yes")),         # Yes, the second level, is what we're modeling
         female = factor(female),                             # Make categorical variables into factors
         job = factor(job),                                   # Otherwise tree won't fit correctly
         rent = factor(rent),
         own_res = factor(own_res),
         new_car = factor(new_car),
         mobile = factor(mobile),
         chk_acct = factor(chk_acct),
         sav_acct = factor(sav_acct)) -> advise_invest        # Save to object

summary(advise_invest)
```

Here is the tree you fit in the previous project:

```{r}
# Create tree model
tree_model <- rpart(answered ~ ., 
                     data = advise_invest)

# Display tree model
tree_model

```

Complicated! Let's practice reading the information from the first split in this tree. Remember that the legend at the top of the output can assist in decoding this information.

node), split, n, loss, yval, (yprob)

1)  root 29499 13375 yes (0.4534052 0.5465948)

The first node is the root node, consisting in the data before any splits. Here we can see that there are 29499 observations, the majority class is "yes" (yval), and that after predicting "yes" (as the majority class), we would be wrong in 13375 cases (loss). The levels in `answered` have a sequence of "no" then "yes" (defined above when we factored the variable); the default in the algorithm is to model the second level, so we are modeling "yes." Which level we are modeling doesn't change the tree or its predictive properties, just its interpretation. In the root node, 55% of the data is "yes," the majority class, and 45% is "no. That is the information in parentheses: (0.4534052 0.5465948). How do we know the order is"no" then "yes"? Because that is the order of the factor levels we set.

2)  chk_acct=0,1,2 19199 8000 no (0.5833116 0.4166884)
3)  chk_acct=3 10300 2176 yes (0.2112621 0.7887379)

The first split, creating nodes 2 (at the top of the output) and 3 (at the bottom), is on checking account where categories are 0, 1, or 2, on the one hand, or 3, on the other. Neither of these are terminal nodes, meaning that they do not produce customer segments; there will be additional splits before we get to final segments with predicted labels. Focusing on 2): 19199 observations wound up in this node, 8000 of which were incorrectly classified. The majority class is "no" at 58%.

4)  income>=79840 1728 192 no (0.8888889 0.1111111) *

5)  income< 79840 17471 7808 no (0.5530880 0.4469120)

6)  is the first terminal node, resulting in a customer segment. It depends on the prior split. So, for customers with checking accounts equal to 0, 1, or 2 AND income greater than or equal to 79840, then predicted label is "no" because that is the majority class in the node, at 89%. 1728 customers wound up in the segment, and predicting no for those customers would have resulted in 192 incorrect classifications.

Etc.

Here is the plot:

```{r}
# Plot tree model
rpart.plot(tree_model)
```

Hard to read! Play around with the tweak argument:

```{r}
# Make plot bigger
rpart.plot(tree_model, tweak = 2, roundint=T)
```

Too busy! There is overplotting.

```{r}
# Adjust plot size down slightly
rpart.plot(tree_model, tweak = 1.6, roundint = T)
```

Just right. Different computer systems will require different size adjustments, it seems.

In a classification tree the predictors that are most strongly associated with the target occur closest to the root, that is, near the top of the tree. This information is useful for descriptive purposes, for example to help a business understand their customers.

The top three predictors of answering in this model are: number of checking accounts, income, and mobile. (This was somewhat ambiguous: you may have answered income greater than or less than 79840 and income greater than or less than 38910. That would be fine.)

Remember the tree model just consists in a set of rules. The rules are defined by the intersecting conditions in the branches. As mentioned above, if chk_acct = 0,1,2 AND income>=79840 then predict "no."

It would be cumbersome to have to apply the rules to each customer. R will do that work for you. Here is how to use this model to predict a class label for each customer:

```{r}
# Predict class label for each customer
predict(object = tree_model, type = "class") |> 
  head
```

This means that the model predicts customer 1 will answer, customer 2 will answer, etc. The `predict()` function simply runs each customer through the classification tree to find out which terminal node they wind up in.

The argument `type = "class"` means that the `predict()` function will predict a class label. But we could also predict a probability by changing `type = "class"` to `type = "prob"`.

```{r}
# Predict probability for each customer
predict(tree_model, type = "prob") |> 
  head
```

Accuracy of the tree model can be calculated using `predict()`. Accuracy is simply the proportion of correct predictions. Accuracy can be calculated in this case because we are predicting something we already know, which allows us to compare the prediction with the observed truth.

```{r}
# Compare predictions to observed truth

# predict(tree_model, type = "class") == advise_invest$answered 

```

Note: Make sure to comment this line out when compiling your notebook. Otherwise it will create a very long document!

This produces TRUEs and FALSEs, as you can see. `mean()` will calculate the proportion of TRUEs.

```{r}
# calculate accuracy
(predict(tree_model, type = "class") == advise_invest$answered) |> 
  mean

```

## Aside: entropy and information gain.

A tree model might seem really complicated, but is actually quite simple once you know the formulas for entropy and information gain.

$$Entropy = -p_1  log(p_1) - p_2  log(p_2) ...$$, where p stands for the proportion of a class label in the node.

The log in question is log base 2. Log base 2 is the number to which 2 would need to be raised to equal the input. So log base 2 of 2 is the the power on 2 that would equal 2, which is 1:

```{r}
log2(2)
```

The transformation looks like this:

```{r}
data.frame(x = seq(.01, 3, .001)) |> # log is undefined for x <= 0
  mutate(log_x = log2(x)) |> 
  ggplot(aes(x, log_x))+
  geom_line(col = 2)+
  theme_minimal() +
  labs(title = "x vs. log2(x)")


```

Calculating entropy is easy: suppose that the proportions of labels in a node are .5 and .5. This is perfectly balanced so we would expect entropy to be 1.

```{r}
-.5 * log2(.5) - .5 * log2(.5)
```

Information gain is also simple---it captures *the change in entropy resulting from a split*---but involved to calculate:

$$IG(parent, children) = Entropy(parent) - [p(child_1)entropy(child_1) - p(child_2)entropy(child_2)]$$,

where p is the proportion of the data winding up in the node.

## Example Code for Project

What do you need to know for this module's project?

1.  Fit a tree model using all the available predictors.
2.  Create a confusion matrix using `predict()` with the `type = "class"` argument and identify numbers of TP, FP, TN and FN.
3.  Estimate profit (benefits - costs) using a defined cost-benefit matrix and the above confusion matrix.
4.  Use the model to predict on a new data set (without the target), then use these predictions to identify those who should be called---a contact list.
5.  Make a recommendation to the Director of Sales based on your analytic work.

Note: For the module 5 project you will predict answering for prospective customers (who have not yet been called). Consequently, the assignment requires an additional data set, customer_data.csv, that you will need to download and move into your project folder. There is code included in the template to load that data into memory after you have it saved in your project folder (your working directory). This code is included in the template script at Canvas.

We will again use the MegaTelCo data for this demonstration.

```{r}
# Load and clean data--recycle code from last project demo

m <- read.csv("megatelco.csv")

m |> 
  mutate(reported_satisfaction = factor(reported_satisfaction,
                                        levels = c("low","avg", "high"),
                                        ordered = T),
         reported_usage_level = factor(reported_usage_level,
                                       levels = c("low", "avg", "high"),
                                       ordered = T),
         considering_change_of_plan = factor(considering_change_of_plan,
                                             levels = c("no", "maybe", "yes")),
         leave = factor(leave), # let the levels be assigned alphabetically
         college = ifelse(college=="one", "yes", "no"),
         college = factor(college)) |> 
  filter(income > 0,
         house > 0,
         handset_price < 1000) |> 
  select(-id) |> 
  na.omit -> m_clean 

# Check whether the operation was successful
summary(m_clean)

```

### Fit a classification tree and create a confusion matrix

Fit a tree model and summarize the results in a confusion matrix using the default class decision threshold produced by using the `type =`class"`argument to`predict()\`. Report the counts in the cells.

```{r}
classification_tree <- rpart(leave ~., data = m_clean)

classification_tree

table(predicted = predict(classification_tree, type = "class"),
      observed = m_clean$leave)

```

In the MegaTelCo case our objective is to model leave. Correctly predicting leave is therefore a true positive, represented in the upper left cell in the matrix. Incorrectly predicting leave---we predict leave but the customer stays---is a false positive, in the upper right cell. Typically, in a case like this one we would only consider predictions of leave to be actionable. That is because if a customer is predicted to stay then, logically, no intervention is necessary. We will therefore ignore the second row in this confusion matrix.

Be aware that, depending on the factor levels in your data, the location of true positives and false positives in the confusion matrix can change!

### Calculate profit 

Using the confusion matrix in the previous question how much profit (revenue - costs) could be expected with these costs-benefits?

- For MegaTelCo we will assume benefit = 800 and cost = 200. 
- TPs are a benefit, FPs are a cost. 
- We ignore those predicted who are predicted to stay. 

Why are TPs a benefit? In the MegaTelCo scenario, these are customers who are predicted to leave. If your marketing campaign is successful, then you can convince them to stay, thereby saving the company money. (In the AdviseInvest scenario, TPs are customers that you have predicted will answer the phone and do answer, thus providing an opportunity for your sales reps to make a sale.)

```{r}
table(predicted = predict(classification_tree, type = "class"),
      observed = m_clean$leave)

1930 * (800 - 200) - 919 * 200
```

### Predict for new data and create a customer contact list

Predict whether existing Megatelco customers will leave.  (In AdviseInvest you will be predicting whether prospective customers will answer the phone.)  

Key idea: The distinction between modeling and using the model.

So far in the course we have been modeling. The presence of a target variable allows us to create a model that relates predictor variables to the target. In the case of a classification tree, the result is a set of rules that leads to a prediction for customers for whom the target variable has already been observed. But ultimately the reason for modeling is to create a model that can be used --- with new data! Once we have a model then we are able to predict a class label for customers for whom the target variable has not been observed. For this we use the `predict()` function. It works just fine without a target variable in the input data set.

We will create a fake new dataset based on the original, just for illustration, with no target. (Note: you would never do this in reality. This code is just for illustration!!! For the AdviseInvest project the new data on prospective customers has been provided for you.)

```{r}
# For illustration only: we create new data set, take out target, and add fake id.  As noted above,
# this is not part of the module 5 project!! For the project this data is already supplied for you
# in customer_data.csv.

set.seed(123) # The seed guarantees we get exactly the same data set after randomly subsetting
new_customers <- m_clean |> 
  sample_n(1000) |> 
  select(-leave) |>  
  mutate(id = sample(1:1000, 1000, replace = F))

str(new_customers)

```

Get predictions for current customers:

```{r}
# generate predictions
predictions <- predict(object = classification_tree, 
        newdata = new_customers,
        type = "class") 

# examine predictions
head(predictions)
```

Add the predictions to the data set and filter for those predicted to leave. Select just `id` and `predictions` for a contact list.

```{r}

contact_list <- new_customers |>                       # Start with customer list
  mutate(predicted_churn = predict(classification_tree, # Add predictions
                              newdata = new_customers,
                              type = "class")) |> 
  filter(predicted_churn == "LEAVE") |>                # Filter list
  select(id, predicted_churn)                           # Select the important columns


contact_list

str(contact_list)

```

Here there are just 577 out of 1000 customers who should be contacted in order to optimize profit.

### Recommendation

Make a recommendation based on the analytics you have done. This should be a carefully thought out, well-reasoned, and well-written recommendation in the neighborhood of 2 - 4 paragraphs. Plus for using tables and plots!

It is critical to think through exactly how the company will use the analytics you have produced. It is your responsibility as the analytics guru to tell them what to do.
