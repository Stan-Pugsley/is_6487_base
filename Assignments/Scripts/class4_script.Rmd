---
title: "Class 4 script"
output: html_document
---

```{r setup, include=FALSE}
# Load libraries
library(tidyverse)
library(rpart)  # Install this:  install.packages("rpart")
library(rpart.plot) # Install this:  install.packages("rpart.plot")
```


## Module 4 Project 

What do you need to be able to do?

    a. Understand model accuracy.  Why is it a performance metric for classification and not regression?
    
    b. Calculate accuracy for a simple majority class model (this is the same as calculating the proportion of the majority class in a binary variable). Consider: x <- c(1, 1, 1, 0, 0).  What is the majority class? What is the proportion of the majority class in x?
    
    c. Fit a tree model of the target with just one predictor variable and calculate the accuracy of this model.
    
    d. Interpret a tree model, and calculate information gain.
    
    e. Fit a tree model of the target using all the predictors, then:  create a visualization of the tree and identify the top 3 most important predictors in this model.
    
    f. Answer the question: how do these models compare to majority class prediction?
    
    g. Answer: How will you use a classification model as part of a solution to the AdviseInvest case?

We will use the MegaTelCo data for this demonstration.

```{r}
# Load and clean data

m <- read_csv(file = "https://raw.githubusercontent.com/Stan-Pugsley/mktg_6487_base/main/Assignments/DataSets/megatelco.csv")


m_clean <- m |> 
  mutate(reported_satisfaction = factor(reported_satisfaction),
         reported_usage_level = factor(reported_usage_level),
         considering_change_of_plan = factor(considering_change_of_plan),
         leave = factor(leave), 
         college = ifelse(college=="one", "yes", "no"),
         college = factor(college)) |> 
  filter(income > 0,
         house > 0,
         handset_price < 1500) |> 
  select(-id) |> # Remove ID because it is not relevant as a predictor
  na.omit ()

# Check whether the operation was successful
summary(m_clean)

```

### Calculate distribution of the outcome

What is the proportion of people who churned?

```{r}
# Could use the numbers from the above summary:

7470 / (7470 + 7521)
 
# Other methods
ifelse(m_clean$leave == "LEAVE", 1, 0) |> 
  mean()

mean(m_clean$leave=="LEAVE")

```

Obviously, if `leave` were expressed as 0/1, then:  `mean(m_clean$leave).`

Why should we care about this proportion?

1. An important step in EDA is to understand the distribution of the target variable.

2. The majority class in the target variable will serve as an important benchmark for model performance. If we used what we'll call a "majority class classifier"---this consists in always predicting the majority class, which in this case is `STAY`---we would be correct 1 - .49 or 51% of the time.  Another way of saying this is that majority class classifier in the MegaTelCo case would result in accuracy of .51.  

Accuracy is defined as the proportion of correctly predicted labels. It is a commonly used error metric for evaluating classifier performance.

Think about why a majority class model in this case would have an accuracy of .51.

Whatever later model we develop should have better accuracy than this performance benchmark.

### Fit a tree model

Use just one variable, `income`. We'll call this the "money tree." What is the accuracy of the money tree?  

```{r}
# Needs rpart library! Make sure you have run:
# library(rpart)

(money_tree <- rpart(formula = leave ~ income, 
                     data = m_clean))

# The formula, y ~ x, means "y explained by x." 
# This is a common syntax for defining a model in R. 

```

Plot the money tree.

```{r}
# Needs rpart.plot library! Make sure you have run:
# library(rpart.plot)

rpart.plot(x = money_tree)

# x is a model object created by rpart().

```

How do we read this plot? Keep in mind that different plotting software will have different ways of representing the information.

Let's start at the top, with the root node. Each node contains three pieces of information:

1.  The majority class in the node, which in the case of the entire data set is STAY.

2.  The proportion of STAY in the node. Why STAY? Because of the structure of the factor variable: it has two levels LEAVE and STAY, and the factors levels are set alphabetically by default. The software automatically uses the second level, STAY.

3.  The percentage of data in the node after the split (if any). Here, because we are dealing with the entire data set, it is 100%.

Take the node on the right as another example. The first (and only) split in the tree is on 100k (rounding up from the actual number of 99993). The right split says "no," which means that it contains customers who make less than 100k.

1.  The majority class label in this node is STAY.
2.  The proportion of STAY in the node is .56.
3.  66% of the data wound up in this node after the split.

What is the accuracy of the money_tree? Use these steps to calculate accuracy.

1.  Get predictions. Use `predict()` with the `type` argument set to "class." The syntax is: `predict(model, type = "class")`. This will return predicted class labels. 

```{r}
predict(money_tree, 
        type = "class") |> 
  head ()

# The point of this code chunk is to show how predict() works.
# We are using head() to avoid printing all observations to screen

```

2. Create a vector comparing model predictions to the observed outcomes for each row. If the prediction is the same as the observed, then the result will be TRUE; if it is not the same, the result will be FALSE.  This vector will show whether the model correctly predicted the outcome for each row.

```{r}
(predict(money_tree, type = "class")==m_clean$leave) |> 
  head ()

# The point of this is to show how the code works in this step.
# We are using head() to avoid printing all observations to screen

```

3. Take the mean of that vector to calculate the proportion of Ts.  This is the model's accuracy.

```{r}
(predict(money_tree, type = "class")== m_clean$leave) |> 
  mean () #.57

# mean() will calculate the proportion of TRUEs in this vector. 
```

The money tree model is more accurate than majority class prediction! .51 has increased to .57.

### Visualize tree model.

Fit a tree model of the outcome using all the predictors and visualize the model using `rpart.plot()`. Two arguments to `rpart.plot()` will be useful for creating a legible plot:  `tweak` and `roundint`.  Use the setting recommended in the quiz.  

Based on the plot, what are the most important predictors in this model?

Note: shorthand to add all predictors is: "."

You will get the wrong (different) answer if you have not modeled categorical variables correctly as factors!

Notice that in the module 4 project template there is a code chunk provided for cleaning and preparing the data. Use it! 

```{r}
(leafy_tree <- rpart(formula = leave ~., 
                     data = m_clean,
                     maxdepth = 5,
                     minbucket = 10))

rpart.plot(x = leafy_tree, 
           tweak = 1, 
           roundint = T) 

# You can play around with different values of tweak for legibility
```

The splits higher in the tree are those that maximize IG at any given step. Therefore, the variables closest to the root node are the most important for predicting the target variable: house, income and overage.

### Compare models using accuracy

What is the accuracy of the leafy_tree model? Is it better than the money_tree or better than majority class prediction? 

```{r}
(predict(money_tree, type = "class")== m_clean$leave) |> 
  mean () #.57

(predict(leafy_tree, type = "class")== m_clean$leave) |> 
  mean () #.71
```

Yes, both models are better than the majority class classifier.  The leafy tree model is the best.
